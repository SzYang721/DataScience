#5.2
try<-c(5,100,10000)
p<-rep(1:3)
for(c in 1:3){
p[c]<-1-(1-1/try[c])^try[c]
}
p
p1<-rep(1:100000)
for(x in 1:100000){
p1[x]<-1-(1-1/x)^x
}
xaxis<-c(1:100000)
plot(xaxis,p1,ylim = c(0.6,0.7))
plot(xaxis,p1,ylim = c(0.6,0.7))
store <- rep (NA, 10000)
for (i in 1:10000){
store[i] <- sum ( sample (1:100, rep =TRUE) == 4) > 0
}
mean (store)
#a)
glm.fit <- glm(default ~ income
+ balance, data=Default, family=binomial)
library(ISLR)
View(Default)
#a)
glm.fit <- glm(default ~ income
+ balance, data=Default, family=binomial)
summary(glm.fit)
#b)
nrow<-nrow(Default)
set.seed(888)
sam<-sample(1:10000,5000,replace = FALSE)
train<-Default[sam,]
test<-Default[-sam,]
glm.fit2 <- glm(default ~ income
+ balance, data=train, family=binomial)
summary(glm.fit2)
glm.probs <- predict (glm.fit2, test, type= "response")
glm.pred <- rep(0, 5000)
glm.pred<-ifelse(glm.probs > 0.5,1,0)
test.y<-ifelse(as.factor(test$default)==1,1,0)
table(glm.pred, test.y)
mean(glm.pred!= test.y)
set.seed(1)
sam<-sample(1:10000,5000,replace = FALSE)
train<-Default[sam,]
test<-Default[-sam,]
glm.fit2 <- glm(default ~ income
+ balance, data=train, family=binomial)
summary(glm.fit2)
glm.probs <- predict (glm.fit2, test, type= "response")
glm.pred <- rep(0, 5000)
glm.pred<-ifelse(glm.probs > 0.5,1,0)
test.y<-ifelse(as.factor(test$default)==1,1,0)
table(glm.pred, test.y)
mean(glm.pred!= test.y)
#c)
glm.test<-function(n){
set.seed(n)
sam<-sample(1:10000,5000,replace = FALSE)
train<-Default[sam,]
test<-Default[-sam,]
glm.fit2 <- glm(default ~ income
+ balance, data=train, family=binomial)
summary(glm.fit2)
glm.probs <- predict (glm.fit2, test, type= "response")
glm.pred <- rep(0, 5000)
glm.pred<-ifelse(glm.probs > 0.5,1,0)
test.y<-ifelse(as.factor(test$default)==1,1,0)
table(glm.pred, test.y)
mean(glm.pred!= test.y)
}
k<-c(1:3)
k[1]<-glm.test(888)
k[2]<-glm.test(777)
k[3]<-glm.test(666)
mean(k)
#d)
glm.test2<-function(n){
set.seed(n)
sam<-sample(1:10000,5000,replace = FALSE)
train<-Default[sam,]
test<-Default[-sam,]
glm.fit2 <- glm(default ~ income
+ balance+student, data=train, family=binomial)
summary(glm.fit2)
glm.probs <- predict (glm.fit2, test, type= "response")
glm.pred <- rep(0, 5000)
glm.pred<-ifelse(glm.probs > 0.5,1,0)
test.y<-ifelse(as.factor(test$default)==1,1,0)
table(glm.pred, test.y)
mean(glm.pred!= test.y)
}
y<-c(1:3)
y[1]<-glm.test2(888)
y[2]<-glm.test2(777)
y[3]<-glm.test2(666)
mean(y)
## 5.6
#a)
summary(glm.fit)
#b)
index<-1
boot.fn<-function(Default, index){
glm.fit<-glm(default~income+balance, data = Default[index,], family = binomial)
return(glm.fit$coefficients)
}
boot.fn(Default,100)
#b)
index<-1
boot.fn<-function(Default, index){
glm.fit<-glm(default~income+balance, data = Default[index,], family = binomial)
out<-coef(glm.fit)[2:3]
return(out)
}
boot.fn<-function(Default, index){
glm.fit<-glm(default~income+balance, data = Default[index,], family = binomial)
out<-coef(glm.fit)[2:3]
return(out)
}
n<-nrow(Default)
Index<-sample(1:n,replace = TRUE)
boot.fn(Default,100)
boot.fn<-function(Default, Index){
glm.fit<-glm(default~income+balance, data = Default, family = binomial, subset = Index)
out<-coef(glm.fit)[2:3]
return(out)
}
n<-nrow(Default)
Index<-sample(1:n,replace = TRUE)
boot.fn(Default,100)
n<-nrow(Default)
boot.fn<-function(Default, Index){
glm.fit<-glm(default~income+balance, data = Default, family = binomial, subset = Index)
out<-coef(glm.fit)[2:3]
return(out)
}
n<-nrow(Default)
Index<-sample(1:n,replace = TRUE)
boot.fn(Default,Index)
#c)
library(boot)
boot(Default,boot.fn,100)
function(boot)
fda
?boot()
install.packages("ISLR")
install.packages("ISLR")
library(ISLR)
data(Auto)
med.mpg <- median(Auto$mpg)
med.mpg
mpg01 <- rep(0, n)
mpg01[Auto$mpg>med.mpg] <- 1
mpg01 <- mpg01
summary(as.factor(mpg01))
Auto <- data.frame(mpg01, Auto)
med.mpg <- median(Auto$mpg)
med.mpg
n<-nrow(Auto)
mpg01 <- rep(0, n)
mpg01[Auto$mpg>med.mpg] <- 1
mpg01 <- mpg01
summary(as.factor(mpg01))
Auto <- data.frame(mpg01, Auto)
head(Auto)
#b
library(ggplot2)
c <- ggplot(Auto, aes(y=mpg , x=weight, colour=factor(cylinders)))
c + geom_point()
p1 <- ggplot(Auto, aes(y=mpg , x=displacement,
colour=factor(cylinders))) + geom_point()
p1
p2 <- ggplot(Auto, aes(y=mpg , x=acceleration,
colour=factor(cylinders))) + geom_point()
p2
p3 <- ggplot(Auto, aes(y=mpg , x=year,
colour=factor(cylinders))) + geom_point()
p3
p4 <- ggplot(Auto, aes(factor(origin), mpg)) +
geom_boxplot(aes(fill = factor(origin)))
p4 + scale_fill_discrete(labels=c("American", "European", "Japanese"))
boxplot(myda)
cor(Auto[, 4:9])
#c
set.seed(10)
n <- nrow(Auto)
sam <- sample(1:n, 100)
train <- Auto[-sam,]
test <- Auto[sam, ]
test.y <- test[,1]
test.X <- test[,-c(1:2)]
#d
cor(train[, c(1,4:9)])[,1]
library(MASS)
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight, data=train)
lda.fit
lda.pred <- predict(lda.fit, test)
lda.class <- lda.pred$class
table(lda.class, test.y)
mean(lda.class!= test.y)
#e
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight, data=train)
qda.fit
qda.pred <- predict(qda.fit, test)
qda.class <- qda.pred$class
table(qda.class, test.y)
mean(qda.class!= test.y)
#f
glm.fit <- glm(mpg01 ~ cylinders + displacement + horsepower
+ weight, data=train, family=binomial)
summary(glm.fit)
glm.probs <- predict (glm.fit, test, type= "response")
glm.pred <- rep(0, 100)
glm.pred[glm.probs > 0.5] <- 1
table(glm.pred, test.y)
mean(glm.pred!= test.y)
glm.fit2 <- glm(mpg01 ~ horsepower
+ weight, data=train, family=binomial)
summary(glm.fit2)
glm.probs2 <- predict (glm.fit2, test, type= "response")
glm.pred2 <- rep(0, 100)
glm.pred2[glm.probs2 > 0.5] <- 1
table(glm.pred2, test.y)
mean(glm.pred2!= test.y)
#g
library (class)
set.seed(100)
train.X <- train[,4:7]
train.y <- train[,1]
test.X <- test[,4:7]
test.y <- test[,1]
##
k.use <- 3:25
test.er <- rep(0, length(k.use))
for(c in 1:length(k.use)){
knn.pred <- knn(train.X, test.X, train.y, k=k.use[c])#3 to 25 nearest neighbor
test.er[c] <- mean(knn.pred!=test.y)
}
##
plot(k.use, test.er, type="l", lwd=3)
